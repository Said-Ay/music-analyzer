# --- å¿…è¦ãªé“å…·ã‚’å…¨éƒ¨ã€é“å…·ç®±ã‹ã‚‰å–ã‚Šå‡ºã™ ---
import yt_dlp
import subprocess
import os
import re # æ–‡å­—ã‚’ã‚­ãƒ¬ã‚¤ã«ã™ã‚‹å°‚é–€å®¶
import shutil # ãƒ•ã‚©ãƒ«ãƒ€ã”ã¨å‰Šé™¤ã™ã‚‹å°‚é–€å®¶
import librosa # éŸ³ã®åˆ†æãªã‚‰å½¼ã«ä»»ã›ã‚
import librosa.display
import numpy as np # æ•°å­¦ãŒå¾—æ„ãªå°‚é–€å®¶
from scipy.ndimage import median_filter # ã‚°ãƒ©ãƒ•ã‚’æ»‘ã‚‰ã‹ã«ã™ã‚‹å°‚é–€å®¶
from scipy.signal import find_peaks # ã‚°ãƒ©ãƒ•ã®å±±ã‚’è¦‹ã¤ã‘ã‚‹å°‚é–€å®¶
from music21 import stream, chord # music21ã‹ã‚‰ã¯ã€ã‚³ãƒ¼ãƒ‰åˆ†æã®å°‚é–€å®¶ã ã‘å‘¼ã¶
import matplotlib.pyplot as plt # ã‚°ãƒ©ãƒ•ã‚’æãå°‚é–€å®¶

# ----------------------------------------------------
# â˜… æ©Ÿèƒ½ã”ã¨ã«ã€æ•´ç†ç®±ï¼ˆé–¢æ•°ï¼‰ã‚’ç”¨æ„ã™ã‚‹ â˜…
# ----------------------------------------------------

def download_from_youtube(url, output_filename="audio.mp3"):
    """YouTubeã‹ã‚‰éŸ³å£°ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹å°‚é–€å®¶ (å›ºå®šãƒ•ã‚¡ã‚¤ãƒ«å)"""
    print(f"'{output_filename}' ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­â€¦")
    
    ydl_opts_info = {'quiet': True, 'no_warnings': True}
    with yt_dlp.YoutubeDL(ydl_opts_info) as ydl:
        info = ydl.extract_info(url, download=False)
        title = info.get('title', 'untitled')
        print(f"æ›²å: '{title}'")

    ydl_opts_download = {
        'format': 'bestaudio/best',
        'outtmpl': os.path.splitext(output_filename)[0],
        'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192'}],
        'noplaylist': True
    }
    with yt_dlp.YoutubeDL(ydl_opts_download) as ydl:
        ydl.download([url])
        
    print("ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†ï¼")
    return output_filename

def analyze_music_karute(audio_path, drum_path=None):
    """æ›²ã®BPMã€ã‚­ãƒ¼ã€æ§‹é€ ã‚’åˆ†æã—ã¦ã€Œã‚«ãƒ«ãƒ†ã€ã‚’ä½œæˆã™ã‚‹å°‚é–€å®¶"""
    try:
        print("\n---------------------------------")
        print(f"éŸ³æ¥½åšå£«ãŒ'{audio_path}'ã‚’åˆ†æä¸­â€¦")
        
        y, sr = librosa.load(audio_path)

        print("\nğŸ“‹========= éŸ³æ¥½ã‚«ãƒ«ãƒ† =========ğŸ“‹")

        tempo, _ = librosa.beat.beat_track(y=y, sr=sr)
        print(f" BPM (ãƒ†ãƒ³ãƒ): {np.mean(tempo):.2f}")

        chromagram = librosa.feature.chroma_stft(y=y, sr=sr)
        chroma_mean = np.mean(chromagram, axis=1)
        notes = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']
        key_index = np.argmax(chroma_mean)
        estimated_key_root = notes[key_index]
        
        major_profile = [6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88]
        minor_profile = [6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17]
        chroma_rotated = np.roll(chroma_mean, -key_index)
        major_similarity = np.dot(chroma_rotated, major_profile)
        minor_similarity = np.dot(chroma_rotated, minor_profile)
        estimated_key_mode = "Major" if major_similarity > minor_similarity else "Minor"
        print(f" ã‚­ãƒ¼ (èª¿) ã€€: {estimated_key_root} {estimated_key_mode}")

        # --- ã“ã“ã‹ã‚‰æ§‹é€ åˆ†æ ---
        print("\n æ›²ã®æ§‹é€  (ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã”ã¨ã®é–‹å§‹æ™‚é–“):")
        
        segment_times = []
        # â˜…â˜…â˜… ã“ã“ãŒæ–°ã—ã„æ©Ÿèƒ½ï¼ â˜…â˜…â˜…
        # ã‚‚ã—ãƒ‰ãƒ©ãƒ ã®éŸ³æºãŒã‚ã‚‹ãªã‚‰ã€ãã‚Œã‚’ä½¿ã£ã¦é«˜ç²¾åº¦åˆ†æã™ã‚‹
        if drum_path and os.path.exists(drum_path):
            print("  - ãƒ‰ãƒ©ãƒ ã®ãƒ“ãƒ¼ãƒˆã¨å…¨ä½“ã®ãƒãƒ¼ãƒ¢ãƒ‹ãƒ¼ã‚’å…ƒã«ã€é«˜ç²¾åº¦ã§åˆ†æä¸­â€¦")
            y_drums, sr_drums = librosa.load(drum_path)
            # ãƒ‰ãƒ©ãƒ ã‹ã‚‰æ­£ç¢ºãªãƒ“ãƒ¼ãƒˆä½ç½®ã‚’æ¤œå‡º
            _, beats = librosa.beat.beat_track(y=y_drums, sr=sr_drums)
            beat_times = librosa.frames_to_time(beats, sr=sr_drums)
            
            # å…ƒã®æ›²å…¨ä½“ã®ãƒãƒ¼ãƒ¢ãƒ‹ãƒ¼æƒ…å ±ï¼ˆã‚¯ãƒ­ãƒã‚°ãƒ©ãƒ ï¼‰ã‚’ã€ãƒ‰ãƒ©ãƒ ã®ãƒ“ãƒ¼ãƒˆã«åŒæœŸã•ã›ã‚‹
            beat_chroma = librosa.util.sync(chromagram, beats, aggregate=np.median)

            # é¡ä¼¼åº¦è¡Œåˆ—ï¼ˆè¨­è¨ˆå›³ï¼‰ã‚’ä½œæˆ
            R = librosa.segment.recurrence_matrix(beat_chroma, metric='cosine', sparse=False)
            # è¨­è¨ˆå›³ã‚’æ»‘ã‚‰ã‹ã«ã—ã¦ã€å¤§ããªæ§‹é€ ã‚’è¦‹ã¤ã‘ã‚„ã™ãã™ã‚‹
            R_smooth = median_filter(R, size=(1, 9))
            # å ´é¢è»¢æ›ã®åº¦åˆã„ã‚’ã‚°ãƒ©ãƒ•ã«ã™ã‚‹ï¼ˆãƒãƒ™ãƒ«ãƒ†ã‚£ã‚«ãƒ¼ãƒ–ï¼‰
            novelty_curve = np.sum(np.diff(R_smooth, axis=1)**2, axis=0)
            novelty_curve = np.pad(novelty_curve, (1, 0), 'constant')
            # ã‚°ãƒ©ãƒ•ã®å±±ï¼ˆï¼å ´é¢è»¢æ›ã®ç¬é–“ï¼‰ã‚’è¦‹ã¤ã‘ã‚‹
            peaks, _ = find_peaks(novelty_curve, prominence=np.median(novelty_curve) * 1.5)
            
            # è¦‹ã¤ã‘ãŸå±±ã®ä½ç½®ï¼ˆãƒ“ãƒ¼ãƒˆç•ªå·ï¼‰ã‚’ã€å®Ÿéš›ã®æ™‚é–“ï¼ˆç§’ï¼‰ã«å¤‰æ›
            segment_times = beat_times[peaks]
            # æ›²ã®é–‹å§‹ç‚¹(0ç§’)ã‚’å¿…ãšå«ã‚ã‚‹
            segment_times = np.concatenate(([0], segment_times))

        # ãƒ‰ãƒ©ãƒ éŸ³æºãŒãªã„å ´åˆã¯ã€ä»Šã¾ã§é€šã‚Šã®ã‚·ãƒ³ãƒ—ãƒ«ãªæ–¹æ³•ã§åˆ†æ
        else:
            print("  - éŸ³é‡ã®å¤‰åŒ–ã‚’å…ƒã«ã€ã‚·ãƒ³ãƒ—ãƒ«ã«åˆ†æä¸­â€¦")
            segment_boundaries_samples = librosa.effects.split(y, top_db=25)
            segment_times = librosa.samples_to_time([boundary[0] for boundary in segment_boundaries_samples], sr=sr)
        
        segment_labels = ['ã‚¤ãƒ³ãƒˆãƒ­', 'Aãƒ¡ãƒ­', 'Bãƒ¡ãƒ­', 'ã‚µãƒ“', 'Cãƒ¡ãƒ­', 'é–“å¥', 'ã‚¢ã‚¦ãƒˆãƒ­']
        for i, t in enumerate(segment_times):
            label = segment_labels[i] if i < len(segment_labels) else f"ã‚»ã‚¯ã‚·ãƒ§ãƒ³{i+1}"
            print(f"  - {label}: {t:.2f}ç§’ ã‹ã‚‰")

        print("ğŸ“‹==============================ğŸ“‹\n")

        # --- æ§‹é€ ã‚’å¯è¦–åŒ–ã—ã¦ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ ---
        fig, ax = plt.subplots(figsize=(12, 4))
        librosa.display.waveshow(y, sr=sr, ax=ax, alpha=0.5)
        ax.vlines(segment_times, -1, 1, color='r', linestyle='--', label='ã‚»ã‚¯ã‚·ãƒ§ãƒ³åŒºåˆ‡ã‚Š')
        ax.set_title('Song Waveform and Structure')
        ax.legend()
        plt.tight_layout()
        
        base_filename = os.path.splitext(audio_path)[0]
        plot_filename = f"{base_filename}_structure.png"
        plt.savefig(plot_filename)
        plt.close(fig) # ãƒ¡ãƒ¢ãƒªã‚’è§£æ”¾
        print(f"'{plot_filename}' ã«æ§‹é€ ã®ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")


    except Exception as e:
        print(f"éŸ³æ¥½åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


def separate_instruments(audio_path, stems=4):
    """demucsã§æ¥½å™¨ã‚’åˆ†é›¢ã™ã‚‹å°‚é–€å®¶ (å›ºå®šãƒ•ã‚©ãƒ«ãƒ€å)"""
    print("---------------------------------")
    print(f"æ¥½å™¨ã®åˆ†æï¼ˆ{stems}ãƒ‘ãƒ¼ãƒˆåˆ†é›¢ï¼‰ã‚’é–‹å§‹â€¦")
    
    output_folder = "separated"
    
    absolute_audio_path = os.path.abspath(audio_path)
    
    command = ["py", "-m", "demucs", "--mp3", "-o", output_folder, absolute_audio_path]
    if stems == 2:
        command.append("--two-stems=vocals")
    
    subprocess.run(command)
    print("éŸ³æºåˆ†é›¢å®Œäº†ï¼")
    
    input_filename_stem = os.path.splitext(os.path.basename(audio_path))[0]
    result_folder = os.path.join(output_folder, "htdemucs", input_filename_stem)

    if os.path.exists(result_folder):
        print(f"\nğŸ‰ğŸ‰ğŸ‰ ãŠã‚ã§ã¨ã†ï¼ ğŸ‰ğŸ‰ğŸ‰")
        print(f"'{result_folder}' ã®ä¸­ã«ã€ãƒ‘ãƒ¼ãƒˆåˆ¥ã®éŸ³æ¥½ãƒ•ã‚¡ã‚¤ãƒ«ãŒä¿å­˜ã•ã‚ŒãŸã‚ˆã€‚")
        # ãƒ‰ãƒ©ãƒ ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’è¿”ã™
        drum_path = os.path.join(result_folder, "drums.mp3")
        return drum_path if os.path.exists(drum_path) else None
    else:
        print("\nã‚ã‚Œï¼Ÿåˆ†é›¢ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã¿ãŸã„â€¦ã€‚")
        return None

# ----------------------------------------------------
# â˜… ãƒ¡ã‚¤ãƒ³ã®æŒ‡æ®è€… â˜…
# ----------------------------------------------------

def main():
    """
    ãƒ—ãƒ­ã‚°ãƒ©ãƒ å…¨ä½“ã®æµã‚Œã‚’æŒ‡æ®ã™ã‚‹ã€ãƒ¡ã‚¤ãƒ³ã®é–¢æ•°ã€‚
    """
    # æœ€åˆã«ã€å‰å›ã®çµæœãŒæ®‹ã£ã¦ã„ãŸã‚‰ãŠæƒé™¤ã™ã‚‹
    if os.path.exists("audio.mp3"):
        os.remove("audio.mp3")
    if os.path.exists("separated"):
        shutil.rmtree("separated")
    for item in os.listdir('.'):
        if item.endswith("_structure.png"):
            os.remove(item)


    # 1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«è³ªå•ã™ã‚‹
    youtube_url = input("åˆ†æã—ãŸã„YouTubeå‹•ç”»URLã‚’è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„: ")
    structure_mode = input("æ›²ã®æ§‹é€ ã‚’ã€ãƒ‰ãƒ©ãƒ ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰é«˜ç²¾åº¦ã§åˆ†æã—ã¾ã™ã‹ï¼Ÿ (y/n): ")
    
    print("---------------------------------")

    # 2. YouTubeã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹
    downloaded_file = download_from_youtube(youtube_url, "audio.mp3")

    if os.path.exists(downloaded_file):
        drum_path = None
        # é«˜ç²¾åº¦ãƒ¢ãƒ¼ãƒ‰ãŒé¸ã°ã‚ŒãŸã‚‰ã€ã¾ãšæ¥½å™¨åˆ†é›¢ã‚’è¡Œã†
        if structure_mode.lower() == 'y':
            # ãƒ‰ãƒ©ãƒ åˆ†é›¢ã«ã¯4ãƒ‘ãƒ¼ãƒˆåˆ†é›¢ãŒå¿…è¦
            drum_path = separate_instruments(downloaded_file, 4)
        
        # 3. æ›²ã®BPMã¨ã‚­ãƒ¼ã¨æ§‹é€ ã‚’åˆ†æã™ã‚‹
        analyze_music_karute(downloaded_file, drum_path)
        
        # 4. è‡ªå‹•ãŠæƒé™¤æ©Ÿèƒ½
        cleanup_choice = input("\nå‡¦ç†ãŒçµ‚ã‚ã£ãŸã®ã§ã€å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ« ('{}') ã‚’å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿ (y/n): ".format(downloaded_file))
        if cleanup_choice.lower() == 'y':
            os.remove(downloaded_file)
            print(f"'{downloaded_file}' ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")
    else:
        print(f"ã‚¨ãƒ©ãƒ¼: '{downloaded_file}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

    print("---------------------------------")
    print("ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")


# --- ã“ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒå®Ÿè¡Œã•ã‚ŒãŸã‚‰ã€ã¾ãšã“ã“ãŒå‘¼ã°ã‚Œã‚‹ ---
if __name__ == "__main__":
    main()
